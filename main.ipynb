{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77895fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .env\n"
     ]
    }
   ],
   "source": [
    "%%writefile .env\n",
    "POLYGON_API_KEY=l7eyBqnxp9XsobMxIBIVHx69zqRlY5rc\n",
    "COHERE_API_KEY=xFDQUTLDdIZJQ4fIyJaLoKtYZTeBvIFpInEAmAbg\n",
    "NEWS_API_KEY = 7bd98c5b274c406180643c142b572c68"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8adeb57",
   "metadata": {},
   "source": [
    "### NEWS Search Module(not necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf340d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing news_api_module.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile news_api_module.py\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "NEWS_API_KEY = os.getenv('NEWS_API_KEY')\n",
    "\n",
    "def newsapi_search_news(company_name: str):\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    \n",
    "    # è·å–å½“æœˆæ—¥æœŸèŒƒå›´\n",
    "    current_date = datetime.now()\n",
    "    from_date = current_date.replace(day=1).strftime('%Y-%m-%d')\n",
    "    \n",
    "    headers = {\n",
    "        \"X-API-Key\": NEWS_API_KEY\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        \"q\": f\"{company_name} AND (stock OR finance OR earnings OR market)\",\n",
    "        \"from\": from_date,\n",
    "        \"language\": \"en\",\n",
    "        \"sortBy\": \"relevancy\",\n",
    "        \"pageSize\": 100\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    \n",
    "    # è¿‡æ»¤å½“æœˆæ–‡ç« \n",
    "    current_month = current_date.month\n",
    "    current_year = current_date.year\n",
    "    \n",
    "    filtered_articles = []\n",
    "    for article in data.get(\"articles\", []):\n",
    "        if article[\"description\"]:\n",
    "            pub_date = datetime.fromisoformat(article[\"publishedAt\"].replace('Z', '+00:00'))\n",
    "            if pub_date.month == current_month and pub_date.year == current_year:\n",
    "                filtered_articles.append({\n",
    "                    'description': article['description'],\n",
    "                    'title': article['title'],\n",
    "                    'datePublished': article['publishedAt']\n",
    "                })\n",
    "    \n",
    "    return filtered_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b899d12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data_module.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_module.py\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import os\n",
    "\n",
    "load_dotenv()  # This loads the variables from .env\n",
    "\n",
    "POLYGON_API_KEY = os.getenv('POLYGON_API_KEY')\n",
    "\n",
    "# Monthly Stock Price History Data\n",
    "def get_stock_price_history(ticker: str, start_date: str, end_date: str):\n",
    "  # Polygon.io API URL for AAPL stock data\n",
    "  url = f'https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/month/{start_date}/{end_date}?apiKey={POLYGON_API_KEY}'\n",
    "\n",
    "  # Make the GET request\n",
    "  response = requests.get(url)\n",
    "\n",
    "  # Check if the request was successful\n",
    "  if response.status_code == 200:\n",
    "      # Parse the JSON data\n",
    "      data = response.json()\n",
    "      return [result['vw'] for result in data['results']]\n",
    "  else:\n",
    "      print(f'Failed to retrieve data: {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81f2037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing calendar.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile date_utils.py\n",
    "import datetime\n",
    "import calendar\n",
    "\n",
    "def get_first_last_days():\n",
    "    # Get the current date\n",
    "    current_date = datetime.date.today()\n",
    "\n",
    "    # Calculate 5 months ago (for start date: 5 months ago, day 1)\n",
    "    start_year, start_month = current_date.year, current_date.month\n",
    "    for _ in range(5):  # Go back 5 months\n",
    "        if start_month == 1:\n",
    "            start_month = 12\n",
    "            start_year -= 1\n",
    "        else:\n",
    "            start_month -= 1\n",
    "    \n",
    "    # Start date: first day of 5 months ago\n",
    "    start_date = datetime.date(start_year, start_month, 1)\n",
    "\n",
    "    # Calculate last month (for end date: last month, last day)\n",
    "    if current_date.month == 1:\n",
    "        last_month = 12\n",
    "        last_year = current_date.year - 1\n",
    "    else:\n",
    "        last_month = current_date.month - 1\n",
    "        last_year = current_date.year\n",
    "    \n",
    "    # End date: last day of last month\n",
    "    last_day_of_last_month = calendar.monthrange(last_year, last_month)[1]\n",
    "    end_date = datetime.date(last_year, last_month, last_day_of_last_month)\n",
    "\n",
    "    # Format the dates\n",
    "    start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Generate month labels: 4 months starting from 4 months ago (skip the 5 months ago start month)\n",
    "    year_month_labels = []\n",
    "    year, month = start_year, start_month\n",
    "    # Skip first month (5 months ago), start from 4 months ago\n",
    "    month += 1\n",
    "    if month > 12:\n",
    "        month = 1\n",
    "        year += 1\n",
    "    \n",
    "    for _ in range(4):  # 4 consecutive months: 4,3,2,1 months ago\n",
    "        year_month_labels.append(f\"{year}-{str(month).zfill(2)}\")\n",
    "        month += 1\n",
    "        if month > 12:\n",
    "            month = 1\n",
    "            year += 1\n",
    "\n",
    "    return start_date_str, end_date_str, year_month_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5320b31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "# åªå¯¼å…¥éœ€è¦çš„transformersæ¨¡å—ï¼Œé¿å…TensorFlowå†²çª\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "class StockLSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=64, num_layers=2, output_size=1, dropout=0.2):\n",
    "        \"\"\"\n",
    "        LSTMæ¨¡å‹ç”¨äºè‚¡ä»·é¢„æµ‹\n",
    "        Args:\n",
    "            input_size: è¾“å…¥ç‰¹å¾æ•°é‡ï¼ˆæ¶¨å¹… + æƒ…æ„ŸæŒ‡æ ‡ = 2ï¼‰\n",
    "            hidden_size: LSTMéšè—å±‚å¤§å°\n",
    "            num_layers: LSTMå±‚æ•°\n",
    "            output_size: è¾“å‡ºå¤§å°ï¼ˆ1è¡¨ç¤ºé¢„æµ‹ä¸‹ä¸ªæœˆçš„æ¶¨å¹…ï¼‰\n",
    "            dropout: dropoutç‡\n",
    "        \"\"\"\n",
    "        super(StockLSTMRegressor, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                           dropout=dropout if num_layers > 1 else 0,\n",
    "                           batch_first=True)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Linear layer for final prediction\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, input_size)\n",
    "        # sequence_length = 4 (è¿‡å»4ä¸ªæœˆ)\n",
    "        # input_size = 2 (æ¶¨å¹… + æƒ…æ„ŸæŒ‡æ ‡)\n",
    "\n",
    "        # åˆå§‹åŒ–éšè—çŠ¶æ€\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "\n",
    "        # Dropout\n",
    "        out = self.dropout(last_output)\n",
    "\n",
    "        # Linear layer\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "def calculate_sentiment_score(headlines, finbert_model, tokenizer):\n",
    "\n",
    "    if not headlines:\n",
    "        return 0.0\n",
    "\n",
    "    sentiment_scores = []\n",
    "    \n",
    "    try:\n",
    "        device = next(finbert_model.parameters()).device\n",
    "    except:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    for headline in headlines:\n",
    "        try:\n",
    "            # ä½¿ç”¨FinBERTè®¡ç®—æƒ…æ„Ÿå¾—åˆ†\n",
    "            encoded = tokenizer.encode_plus(\n",
    "                headline,\n",
    "                add_special_tokens=True,\n",
    "                max_length=64,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            # ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡\n",
    "            input_ids = encoded['input_ids'].to(device)\n",
    "            attention_mask = encoded['attention_mask'].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = finbert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "                logits = outputs.logits\n",
    "                probabilities = torch.softmax(logits, dim=-1).cpu().numpy()[0]\n",
    "\n",
    "                # FinBERTè¾“å‡º: [negative, neutral, positive]\n",
    "                # è½¬æ¢ä¸ºè¿ç»­çš„æƒ…æ„Ÿå¾—åˆ†: positive - negative\n",
    "                weighted_score = probabilities[0] - probabilities[1]\n",
    "                sentiment_scores.append(weighted_score)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"å¤„ç†æ ‡é¢˜æ—¶å‡ºé”™: {headline[:50]}... é”™è¯¯: {e}\")\n",
    "            # å‡ºé”™æ—¶ä½¿ç”¨ä¸­æ€§å¾—åˆ†\n",
    "            sentiment_scores.append(0.0)\n",
    "\n",
    "    return float(np.mean(sentiment_scores)) if sentiment_scores else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba03e450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import calendar\n",
    "import requests\n",
    "from date_utils import get_first_last_days\n",
    "from data_module import get_stock_price_history\n",
    "from model import StockLSTMRegressor, calculate_sentiment_score\n",
    "\n",
    "# å…¨å±€å˜é‡ï¼ˆä¼šè¢«å¤–éƒ¨ç¨‹åºè®¾ç½®ï¼‰\n",
    "API_KEY = \"l7eyBqnxp9XsobMxIBIVHx69zqRlY5rc\"\n",
    "base_url = \"https://api.massive.com/v2/reference/news\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def calculate_monthly_returns(prices):\n",
    "    \"\"\"è®¡ç®—æœˆåº¦æ¶¨å¹…\"\"\"\n",
    "    if not prices or len(prices) < 2:\n",
    "        return []\n",
    "    \n",
    "    returns = []\n",
    "    for i in range(1, len(prices)):\n",
    "        monthly_return = (prices[i] - prices[i-1]) / prices[i-1]\n",
    "        returns.append(monthly_return)\n",
    "    return returns\n",
    "\n",
    "def predict_stock_end_to_end(ticker_symbol: str, model_path: str = r\"C:\\Users\\14869\\Desktop\\Fintech\\Pro_web\\model\\LSTM_FINTECH.pth\"):\n",
    "    result = {\n",
    "        'ticker': ticker_symbol,\n",
    "        'success': False,\n",
    "        'predicted_return': None,\n",
    "        'predicted_price': None,\n",
    "        'current_price': None,\n",
    "        'monthly_data': {},\n",
    "        'news_by_month': {},\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # è·å–å…¨å±€å˜é‡ï¼ˆç”± streamlit åº”ç”¨è®¾ç½®ï¼‰\n",
    "        import builtins\n",
    "        finbert_model = getattr(builtins, 'finbert_model', None)\n",
    "        tokenizer = getattr(builtins, 'tokenizer', None)\n",
    "        api_key = getattr(builtins, 'API_KEY', API_KEY)\n",
    "        base_url_global = getattr(builtins, 'base_url', base_url)\n",
    "        device_global = getattr(builtins, 'device', device)\n",
    "        \n",
    "        print(\"ğŸ“… ç¬¬1æ­¥ï¼šè·å–æ—¥æœŸèŒƒå›´\")\n",
    "        start_date, end_date, target_months = get_first_last_days()\n",
    "        \n",
    "        print(f\"\\nğŸ“° ç¬¬2æ­¥ï¼šæœç´¢ {ticker_symbol} çš„æ–°é—»æ•°æ®\")\n",
    "        news_by_month = {}\n",
    "        \n",
    "        for month_label in target_months:\n",
    "            year, month = month_label.split('-')\n",
    "            last_day = calendar.monthrange(int(year), int(month))[1]\n",
    "            \n",
    "            params = {\n",
    "                \"ticker\": ticker_symbol,\n",
    "                \"published_utc.gte\": f\"{year}-{month}-01T00:00:00Z\",\n",
    "                \"published_utc.lte\": f\"{year}-{month}-{last_day:02d}T23:59:59Z\",\n",
    "                \"limit\": 30,\n",
    "                \"order\": \"descending\",\n",
    "                \"sort\": \"published_utc\",\n",
    "            }\n",
    "            \n",
    "            headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "            resp = requests.get(base_url_global, params=params, headers=headers)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            \n",
    "            news_by_month[month_label] = {\n",
    "                'count': data.get(\"count\", 0),\n",
    "                'articles': data.get(\"results\", [])\n",
    "            }\n",
    "        \n",
    "        total_news = sum(data['count'] for data in news_by_month.values())\n",
    "        print(f\"è·å–åˆ° {total_news} ç¯‡æ–°é—»\")\n",
    "        \n",
    "        print(f\"\\nğŸ’­ ç¬¬3æ­¥ï¼šè®¡ç®—æƒ…æ„Ÿå¾—åˆ†\")\n",
    "        monthly_sentiment_scores = {}\n",
    "        \n",
    "        for month_label, month_data in news_by_month.items():\n",
    "            articles = month_data['articles']\n",
    "            \n",
    "            headlines = []\n",
    "            for article in articles:\n",
    "                title = article.get('title', '')\n",
    "                description = article.get('description', '')\n",
    "                headline = title if title else description\n",
    "                if headline:\n",
    "                    headlines.append(headline)\n",
    "            \n",
    "            sentiment_score = calculate_sentiment_score(headlines, finbert_model, tokenizer)\n",
    "            monthly_sentiment_scores[month_label] = sentiment_score\n",
    "            print(f\"{month_label}: {len(headlines)} æ¡æ–°é—», æƒ…æ„Ÿå¾—åˆ†: {sentiment_score:.3f}\")\n",
    "\n",
    "        print(f\"\\nğŸ“ˆ ç¬¬4æ­¥ï¼šè·å– {ticker_symbol} è‚¡ä»·æ•°æ®\")\n",
    "        stock_prices = get_stock_price_history(ticker_symbol, start_date, end_date)\n",
    "        \n",
    "        if not stock_prices:\n",
    "            raise ValueError(f\"æ— æ³•è·å– {ticker_symbol} çš„è‚¡ä»·æ•°æ®\")\n",
    "        \n",
    "        print(f\"è·å–åˆ° {len(stock_prices)} ä¸ªæœˆçš„è‚¡ä»·æ•°æ®\")\n",
    "        \n",
    "        # ç¬¬5æ­¥ï¼šè®¡ç®—æœˆåº¦æ¶¨å¹…\n",
    "        print(f\"\\nğŸ“Š ç¬¬5æ­¥ï¼šè®¡ç®—æœˆåº¦æ¶¨å¹…\")\n",
    "        monthly_returns = calculate_monthly_returns(stock_prices)\n",
    "        \n",
    "        if len(monthly_returns) != 4:\n",
    "            raise ValueError(f\"æœŸæœ›4ä¸ªæœˆæ¶¨å¹…æ•°æ®ï¼Œå®é™…è·å¾— {len(monthly_returns)} ä¸ª\")\n",
    "        \n",
    "        # ç¬¬6æ­¥ï¼šå‡†å¤‡LSTMè¾“å…¥æ•°æ®\n",
    "        print(f\"\\nğŸ”§ ç¬¬6æ­¥ï¼šå‡†å¤‡LSTMè¾“å…¥æ•°æ®\")\n",
    "        sentiment_values = list(monthly_sentiment_scores.values())\n",
    "        \n",
    "        # åˆ›å»ºç‰¹å¾çŸ©é˜µ\n",
    "        features = []\n",
    "        for i, month in enumerate(target_months):\n",
    "            month_features = [\n",
    "                monthly_returns[i],  # æœˆåº¦æ¶¨å¹…\n",
    "                sentiment_values[i]  # æƒ…æ„Ÿå¾—åˆ†\n",
    "            ]\n",
    "            features.append(month_features)\n",
    "        \n",
    "        features_array = np.array(features, dtype=np.float32)\n",
    "        print(f\"ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {features_array.shape}\")\n",
    "        \n",
    "        # ç¬¬7æ­¥ï¼šåŠ è½½LSTMæ¨¡å‹\n",
    "        print(f\"\\nğŸ¤– ç¬¬7æ­¥ï¼šåŠ è½½LSTMæ¨¡å‹\")\n",
    "        if not os.path.exists(model_path):\n",
    "            raise FileNotFoundError(f\"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}\")\n",
    "        \n",
    "        lstm_model = StockLSTMRegressor(\n",
    "            input_size=2, hidden_size=64, num_layers=2, output_size=1, dropout=0.2\n",
    "        )\n",
    "        \n",
    "        checkpoint = torch.load(model_path, map_location=device_global)\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            lstm_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "            lstm_model.load_state_dict(checkpoint)\n",
    "        \n",
    "        lstm_model = lstm_model.to(device_global)\n",
    "        lstm_model.eval()\n",
    "        \n",
    "        # ç¬¬8æ­¥ï¼šè¿›è¡Œé¢„æµ‹\n",
    "        print(f\"\\nğŸ”® ç¬¬8æ­¥ï¼šè¿›è¡Œè‚¡ä»·é¢„æµ‹\")\n",
    "        input_tensor = torch.from_numpy(features_array).unsqueeze(0).to(device_global)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            prediction = lstm_model(input_tensor)\n",
    "            predicted_return = prediction.item()\n",
    "        \n",
    "        # è®¡ç®—é¢„æµ‹ä»·æ ¼\n",
    "        current_price = stock_prices[-1]\n",
    "        predicted_price = current_price * (1 + predicted_return)\n",
    "        \n",
    "        # ä¿å­˜ç»“æœ\n",
    "        result.update({\n",
    "            'success': True,\n",
    "            'predicted_return': predicted_return,\n",
    "            'predicted_price': predicted_price,\n",
    "            'current_price': current_price,\n",
    "            'monthly_data': {\n",
    "                'months': target_months,\n",
    "                'returns': monthly_returns,\n",
    "                'sentiment_scores': sentiment_values,\n",
    "                'prices': stock_prices\n",
    "            },\n",
    "            'news_by_month': news_by_month\n",
    "        })\n",
    "        \n",
    "        # ç¬¬9æ­¥ï¼šæ˜¾ç¤ºé¢„æµ‹ç»“æœ\n",
    "        print(f\"\\nğŸ¯ é¢„æµ‹ç»“æœ\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"ğŸ“Š è‚¡ç¥¨ä»£ç : {ticker_symbol}\")\n",
    "        print(f\"ğŸ’° å½“å‰ä»·æ ¼: ${current_price:.2f}\")\n",
    "        print(f\"ğŸ¯ é¢„æµ‹ä»·æ ¼: ${predicted_price:.2f}\")\n",
    "        print(f\"ğŸ“ˆ é¢„æµ‹æ¶¨å¹…: {predicted_return:.4f} ({predicted_return*100:.2f}%)\")\n",
    "        \n",
    "        if predicted_return > 0:\n",
    "            print(\"âœ… æ¨¡å‹é¢„æµ‹è‚¡ä»·å°†ä¸Šæ¶¨\")\n",
    "        else:\n",
    "            print(\"âš ï¸ æ¨¡å‹é¢„æµ‹è‚¡ä»·å°†ä¸‹è·Œ\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ è¾“å…¥ç‰¹å¾è¯¦æƒ…:\")\n",
    "        for i, month in enumerate(target_months):\n",
    "            print(f\"   {month}: æ¶¨å¹…={monthly_returns[i]:+.4f}, æƒ…æ„Ÿå¾—åˆ†={sentiment_values[i]:+.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = f\"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}\"\n",
    "        print(f\"âŒ {error_msg}\")\n",
    "        result['error'] = error_msg\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69305d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import calendar\n",
    "import requests\n",
    "\n",
    "# å…¨å±€å˜é‡ï¼ˆä¼šè¢« streamlit åº”ç”¨è®¾ç½®ï¼‰\n",
    "API_KEY = \"l7eyBqnxp9XsobMxIBIVHx69zqRlY5rc\"\n",
    "base_url = \"https://api.massive.com/v2/reference/news\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def calculate_monthly_returns(prices):\n",
    "    \"\"\"è®¡ç®—æœˆåº¦æ¶¨å¹…\"\"\"\n",
    "    if not prices or len(prices) < 2:\n",
    "        return []\n",
    "    \n",
    "    returns = []\n",
    "    for i in range(1, len(prices)):\n",
    "        monthly_return = (prices[i] - prices[i-1]) / prices[i-1]\n",
    "        returns.append(monthly_return)\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c702cb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\14869\\desktop\\fintech\\pro_web\\venv\\lib\\site-packages (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\14869\\Desktop\\Fintech\\Pro_web\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"âœ… {package} å®‰è£…æˆåŠŸ\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ {package} å®‰è£…å¤±è´¥: {e}\")\n",
    "\n",
    "# å®‰è£… python-dotenv\n",
    "install_package(\"python-dotenv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5915f72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 17:47:31.536 Uncaught app execution\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\14869\\Desktop\\Fintech\\Pro_web\\venv\\lib\\site-packages\\streamlit\\runtime\\scriptrunner\\exec_code.py\", line 128, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"c:\\Users\\14869\\Desktop\\Fintech\\Pro_web\\venv\\lib\\site-packages\\streamlit\\runtime\\scriptrunner\\script_runner.py\", line 669, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"c:\\Users\\14869\\Desktop\\Fintech\\Pro_web\\streamlit_main.py\", line 44, in <module>\n",
      "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "NameError: name 'torch' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://192.168.31.53:8501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!streamlit run streamlit_main.py\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
